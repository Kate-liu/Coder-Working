



# 大公司的大数据战略得失：自建轮子成本高

介绍完主流大公司的大数据战略，我们来分析一下这些公司的状况。大体来说，我们可以把这些公司分成两类：一类是自己造轮子的，另一类是在 Hadoop 生态圈里面抱团取暖的。前者主要有三个公司：谷歌、微软和阿里巴巴，后者就是其他我们耳熟能详的大公司了。今天我们就来聊聊自己造轮子的公司。

谷歌自建轮子是一件可以理解的事情，“三驾马车”的出现才真正把人类带入了大数据时代。毕竟没有谷歌就没有大数据，更不会存在“某个软硬件体系可以低成本高效率地解决整个互联网数据的分析和存储”的事情。可以不夸张地说，它的前方基本一片空白，于是在“自建轮子”这件事上，谷歌没有多少选择权。

谷歌的目标是做世界上最好的搜索引擎，因此它需要大数据相关的基础架构。没有这套东西，就没有谷歌这个搜索引擎，有了这套东西，才能继续把搜索做下去。至于这个东西需要消耗多少成本，对谷歌来说都是没有办法的事儿。

更为重要的是，大数据这个概念，以及和这个概念相关的一切技术架构，在谷歌开始发明之前都是不存在。所以谷歌只能选择从无到有自建轮子开发大数据的基础架构。

不过从另一个角度来说，从无到有地把这一套东西搭起来，这无疑也是谷歌对全世界最大的贡献。

至于微软为什么要建设自己的轮子，原因也并不复杂。在微软大规模投钱进入搜索领域的时候，谷歌已经发明了自己的轮子，但是市面上公开的轮子，那个叫 Hadoop 的东西，还非常简陋不好用。

那个年代的微软很傲娇，对待开源相当抵制。看不起 Hadoop 这个在当时看来像是玩具一样的东西，更不要说 Hadoop 又是以微软特别讨厌的 Java 语言开发的。

于是，对于微软来说选择也不多。Hadoop 不可用，谷歌的东西不可得，而微软又非要在那个时间点把搜索做起来，就只能自己搭了。

那时候呢，微软对自己的技术实力、人才储备以及资金都很有信心，所以选择自建轮子时的底气我们是可以想象的。不过，当时的微软是否过度自信了，那就是另外一个问题了。

阿里巴巴是我知道的，第三个自己搭建轮子的公司，它的 MaxCompute 系统，原来叫作 ODPS。

阿里巴巴的系统对于远在美国的我来说更陌生一些。至于为什么阿里巴巴会自己搭建系统，原因我也不是特别清楚，但基本上也不外乎是“开源系统不可用，无意去共建开源系统抱团取暖，又对自己的技术实力、人才储备以及资金有信心”这些原因吧。

但话又说回来，自建轮子是一件非常不容易的事情，特别是当自建轮子的公司希望有所创新，而不是亦步亦趋盲目模仿的时候。

谷歌的不易我们可想而知，从无到有地把东西发明出来，离不开谷歌天才般工程师们的贡献，比如我们现在耳熟能详的杰夫·迪恩（Jeff Dean）就是其中的一员。

有了谷歌的先驱以后，Hadoop 采取的方式是亦步亦趋模仿谷歌的论文；但是 Hadoop 的产品并不好，和谷歌的系统不能比，至今也依然有很多为人诟病的地方。

微软在建设 Cosmos 的时候，和 Hadoop 的做法挺不一样的。Cosmos 是微软投入极其巨大的一个项目，它的投入主要体现在两方面。

一是 Cosmos 的开发团队集中了微软内部各个技术领域的专家精英，涉及了分布式系统，存储，压缩，分布式数据处理，查询优化等多个领域。

二是为了运营 Cosmos，微软投入了好多个数据中心，总机器容量超过 10 万台；而这些机器平均在三年内就会被淘汰。由此可见，为了开发和运营 Cosmos，微软可谓不计血本。

除此之外，为了让 Cosmos 这个产品成熟起来，微软冒了很多风险，也付出了巨大的代价。这些代价和风险体现在两方面。

一方面体现在 Cosmos 系统早期对计算机资源的巨大浪费。在 Cosmos 的早期，由于系统本身开发成熟度不够，于是系统对计算机资源（包括内存、CPU 和网络）的使用都不是最优的，很多时候甚至有效利用率连 50% 都不到。这些被浪费的资源可谓非常巨大。

另外一个方面，为了帮助 Cosmos 早日成熟。必应搜索引擎在 Cosmos 还不够完善的早期阶段，就把很多核心业务从相对稳定的 SQL Server 集群上迁移到 Cosmos 上来，让业务承受巨大风险，和 Cosmos 一起成长和成熟。

在 Cosmos 的早期，因为系统的问题导致计算结果出现错误，进而影响了整个业务的成本和收益的核算，是司空见惯的问题。甚至是类似数据永久丢失这样的事情，也曾经发生过若干次。

其中最为著名的一次是由于 Cosmos 里一个很难发现的 Bug，导致系统误删了大量数据。虽然经历了艰难的数据恢复过程，但是有 10% 的数据依然永久丢失了，这里面就包括必应广告团队的一些核心数据，它们的丢失直接影响了微软广告的营收。

然而，即使是需要如此巨大的投入，即使有可能造成计算资源的极大浪费，甚至可能会让业务陷入非常严重的问题，微软对 Cosmos 的开发、运营和使用的支持仍然始终如一。

据我所知，阿里巴巴的 MaxCompute 平台的发展过程也很类似。比如说，阿里巴巴集团内部把某些贷款业务放在了 MaxCompute 平台上，让业务本身和平台一起成长。这种成本很多时候非常巨大。

自建轮子的成本是非常高的，然而一旦轮子建成并稳定运行以后，其收益也是非常巨大的。无论谷歌、微软还是阿里巴巴，借助其内部平台强大的分析能力，给自身业务的发展提供的强力支持，绝非是一个 Hadoop 平台可以媲美的。

既然自建平台好处多多，为什么没有其他企业自己建设轮子呢？

**首先，有时不是愿不愿意的问题，而是能不能的问题。** 要具备自己建设轮子的能力，并且这个轮子还要好用，确实需要方方面面的积累。在整个互联网行业里，具备自己建设轮子能力的公司，并不是很多。

**其次，这些公司到底有没有自己建轮子的需求。** 这也是一个问题，比如说，做搜索需要存整个互联网的数据，还需要对用户访问互联网的日志文件进行分析，这就对轮子本身能够存储和处理数据的规模提出了很高的要求。在很长一段时间里，Hadoop 是做不到的，但是这个世界上只有少数公司需要如此大规模的数据存储和处理能力。很多公司既然不需要，那么也就不一定非要建设这样的轮子了。

**最后，这还和公司文化有关系。** 对待开源社区的态度，决定了这些公司是愿意合作建轮子，还是自建轮子。

自建轮子解决内部事情，是一个很好的做法，但是不忘初心这件事情也挺难的。那些自建轮子成功解决内部问题的企业，都有把自己建设好的轮子包装一下卖给外部客户的想法。

比如说谷歌搞了 App Engine，让用户可以通过 API 来用它的三架马车。微软则在 2015 年推出了 Cosmos 的企业版：Azure Data Lake。从 ODPS 改名的 MaxCompute 更是阿里巴巴在云端主推的产品。

但是很有意思的是，这些内部非常成功的产品，在对外以云产品销售的过程中，都惨败地一塌糊涂。

没有人买账，这是一个非常有趣的现象。我想原因也是多方面的。第一个方面是 Hadoop 生态圈对大部分企业够用了。大部分企业对数据的处理到不了微软谷歌阿里巴巴的量级，不需要自建的轮子，而 Hadoop 相对普及，大家都用得比较顺手。

第二个方面是这些轮子都是专有工具，使用任何一个专有工具就意味着让自己锁定进了这个平台。这是很多企业不愿意做的。所以成功解决内部需求的自建轮子，却在外部市场上屡屡折戟。

总而言之，自建轮子是一件成本非常高昂的事情，并非对每个企业都适用。所以这个世界上真正自建轮子的企业并不多。每个自建的轮子在服务其内部业务的时候，都很成功。

然而不忘初心这件事情挺难的。每家自建的轮子最终都在试图卖给第三方，却一个也没做成过生意。究其原因，做事情还是需要初心的。当初为了服务内部业务的目的而构建的系统，本非为外部客户服务，结果却强行扭转，非要做成服务外部，犹如强扭的瓜，到底甜不甜，可想而知。







# 大公司的大数据战略得失：抱团取暖难敌插管吸血者

开源项目最讨厌的就是只进不出的参与者。一个公司如果只把开源项目拿去赚钱，却不拿自己的改动和成果反哺社区，开源项目就难以持续发展下去。

所以，抱团取暖的前提是大家都愿意主动贡献自己的成果，但亚马逊是一个另类，它从开源社区拿了很多东西却从不贡献开源。这样只会“插管吸血”的亚马逊，是不是会就此破坏了开源社区良好的氛围呢？

在大数据的发展战略上，除了自建轮子的谷歌、微软和阿里巴巴，各大公司大多走向了一条抱团取暖的道路；而这个抱团取暖的产物，就是你搭一个模块、我搭一个模块，大家一起开源出来，组成了一个叫作 Hadoop 的生态圈。

如果要具体来说一说，雅虎当然是 Hadoop 生态圈里最大的贡献者，但是 Facebook、Twitter 和 LinkedIn 的贡献也不算少。eBay 和 IBM 的功劳自然也不可忽略，大家前前后后都做了不少事。最近来说，加州大学伯克利分校的 AMP 实验室的 Spark 贡献也是十分突出。

为什么这些公司会选择抱团取暖？我简单总结了一下，主要有 3 个原因：

1. 技术和资源储备还不够，单靠自己没法搭建起来；
2. 业务需求不迫切，还没到非要自己搭轮子的地步；
3. 公司可以熟悉开源文化，通过这种方式，公司对开源社区会更加友好。

那么，这些公司的“抱团取暖”带来了哪些好处呢？

首先，这些参与其中的公司们在很长一段时间内保持了亲密合作关系，也很快让 Hadoop 生态圈变得丰富起来，变得越来越可用，越来越实用。

其次，这也让更多并未参与其中的创业公司获得加持，以极低的成本获得了大数据分析的能力。湾区的创业氛围因此变得无比美好，客观来说这样的合作确实促进了创业的发展。毕竟创业者更需要关注业务逻辑，而具体的系统实现可以利用开源社区的产品和架构来快速解决。

只是在很多时候，有钱能捡的话，就一定会有人去捡。随着这个生态圈的壮大，试图通过这个生态圈牟利的人和公司也越来越多，而这在很大程度上违背了雅虎、Facebook、Twitter 和 LinkedIn 等公司最初的设想。

首先出现的当然是把 Hadoop 打包卖给其他企业的公司。Cloudera 就是这样一家公司，MapR 也是，Hortonworks 也是，而最后这家公司干脆原本就是雅虎的 Hadoop 团队，他们看着别人捡钱心里不爽，所以特意从雅虎跳出来创建的。

然而，和当初抱团取暖时“难兄难弟们”的无私贡献相比，因为是带着明确的商业目的，这一类公司对于 Hadoop 的态度就多少有些不一样了。

不过，就算它们的目的是为了把东西卖出去，很多事情还是要做好的。相较来说，毕竟当时的 Hadoop 作为抱团取暖的产物，很多时候只算是一个可以用，却并不是最好用的东西。对于那些传统企业来说，Hadoop 的方方面面都不符合他们的要求，比如安全问题、使用者的权限管理和监控、效率和资源的消耗等等方面都不尽如人意。

这样看来，我们必须说，Cloudera 和 Hortonworks 对于 Hadoop 本身的发展是投入了大量资源的，对于 Hadoop 相关生态圈的模块也是投入了很多人力物力的。即便这些公司是打算靠这个赚钱的，它们也的确是为 Hadoop 生态圈的繁荣贡献了自己的力量。

不过，在 Hadoop 生态圈里面赚钱最多的显然不是这些公司。Hortonworks 股票上市以后估值掉了 50%，Cloudera 在上市前自砍 50% 的估值血淋淋地上市，这两件事情都说明这个行当的利润并没有想象中那么高。这些公司虽然都活着，但是恐怕活得也是有些艰辛。

要是说哪家公司借着 Hadoop 生态圈的东风，迅速青云直上了？无疑是亚马逊。亚马逊的 AWS 之所以能如火如荼地开展起来，离不开 Hadoop 生态圈的贡献。亚马逊的 Elastic MapReduce 服务自推出以后就非常受欢迎，这个云上的 Hadoop 系统，给亚马逊带来了滚滚红利。

但是回头看一下亚马逊到底给这个生态圈做了什么贡献呢？几乎屈指可数。即使不能说是零，起码也可以说是无限接近于零了。虽然它也有一些代码提交，但主要还是为了解决 Hadoop 生态圈与亚马逊其他云服务如何打交道的能力。也就是说，亚马逊做出的最大贡献，是解决了 Hadoop 集群如何同亚马逊的云存储 S3 连接的问题。

一方面是赚到了很多的钱，一方面则是毫无贡献。这个只负责插管吸血的亚马逊，无疑在商业上获得了非常大的成功。而我们也很难去苛责亚马逊，毕竟开源系统拿过来用，回头要不要反哺开源系统，很多时候也只是公司自己决策的问题。

尤其是开源社区的授权方式本身就有很大的 Bug。Hadoop 社区通行的 Apache 授权方式，不要求商业公司必须公开修改后的源代码。即使是更严格的 GPL 授权方式，商业公司依然有无数的办法可以绕过去。所以最终来看，商业公司要不要反哺开源系统，基本上靠大家的自觉。

但是有一点是可以肯定的，如果每个公司都学习亚马逊的做法，那么 Hadoop 生态圈在一开始就不可能构建出来。毕竟如果没有很多互联网公司的开源，也就不可能有完善可用的生态圈。

所以，亚马逊这样的做法，实际上是有碍开源社区繁荣的。我想很多做大数据开源的人，肯定对亚马逊的做法颇有微词。

只是从开源社区来看，Apache 基金会也没有什么行之有效的办法，去阻止别人像亚马逊一样使用这些开源软件，既然没有约束，那么亚马逊的做法则显得合理又合法，那么我们究竟应该用什么态度来看待这样的一家公司呢？

我个人对亚马逊的感情其实是很复杂的。首先，亚马从很多方面来看都是一家伟大的公司，它所推崇并遵循的亚马逊领导力准则，更是值得每一位有志于做出一番事业的互联网从业者认真学习了解，并深刻理解。这些简单而深刻的准则，我不敢说是普遍适用的真理，但是起码对我个人来说受益非常大。

但是从另外一个方面来看，亚马逊这个公司没有“取之于社区，用之于社区”的观念。亚马逊对客户是很好的，对社区就不一定了。一个只是不断从社区获取，却不愿意贡献给社区的公司，破坏的是整个社区的氛围和默契。

如果这个公司籍籍无名，也没有因此发家致富，那它的破坏力还不是那么强。而一个公司如果保持如此作风同时在大量地赚钱，那无疑是树立了一个坏的榜样，这种破坏力是极为巨大的。

开源社区发展到今天，已经度过了不成气候的阶段，现在也有了很多非常有影响力的项目。但是如果还是不能找到有效的管理方式来表彰贡献、控制索取，长久来看可能会出现越来越多对开源“插管吸血”的公司，这对开源社区来说显然会是一件极其不利的事情。

































