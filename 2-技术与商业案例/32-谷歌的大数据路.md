

# 谷歌的大数据路：从“三驾马车”到一无所有

聊起西方文明，我们通常言必称希腊，古希腊有三大哲学家：苏格拉底、柏拉图和亚里士多德。而聊起大数据，我们通常言必称谷歌，谷歌有“三驾马车”：谷歌文件系统（GFS）、MapReduce 和 BigTable。

**就像古希腊的哲学家照亮了西方文明一般，谷歌的“三驾马车”开启了大数据时代，并为我们指明了大数据的发展方向。**

那么，大数据到底是从什么时候火起来的？这个问题并没有一个确切的答案，如果一定要说，2010 年算是初现苗头。

但是，作为大数据时代开拓者的谷歌，它的“三架马车”远远早于 2010 年诞生：谷歌文件系统第一次公开发表的论文是在 2003 年，MapReduce 公开发表的时间是 2004 年，而 BigTable 则公开发表于 2006 年。

谷歌的传统做法向来是先内部使用，等到下一代产品开发得差不多了，再发布这一代的产品。因此，谷歌的“三驾马车”在内部使用的时间更早。

这“三驾马车”，主要是为谷歌的核心搜索业务服务的。作为全球最大的搜索引擎，谷歌需要存储整个互联网的内容，并且要在这个内容的基础上构建倒排索引，这些都是基于“三驾马车”来实现的。

**倒排索引是对互联网内容的一种索引方法，是指从搜索词到对应的互联网文档的索引方法。** 用户可以通过搜索词去搜索互联网，返回的则是和搜索词相关的文档。之所以称为倒排索引，是因为文档到文档里面的词是顺序的，而从文档里面的词到文档是逆序的。

为了构建倒排索引，谷歌首先需要存储整个互联网的内容，并存储构建倒排索引所需的空间。而在当时的技术条件下，世界上是没有现成的产品可以实现这种倒排索引。所以，**谷歌发明了谷歌文件系统，一个基于大量的廉价个人计算机的海量存储系统，它可以轻松地存储整个互联网的内容。**

**MapReduce 则是谷歌构建第一代倒排索引的基础，它可以大规模并行地处理整个互联网上的所有文档**，这是相当令人吃惊的。但是，这个索引构建方法有一个天然的缺陷：每次重新构建索引的时候都需要把整个索引全部推翻重来，而无法做到增量更新。而即使以谷歌的计算能力，重新构建一次索引也需要若干天的时间。这种做法最大的弊端是，新的突然更新的消息无法迅速融入到搜索引擎里。

而互联网内容变化的特点是，热点网站变化非常快，很多非热点网站却可能几个月如一日地没有内容更新。为了让索引的构建可以做到增量更新，即只更新有变化的网站，谷歌发明了 BigTable。

**BigTable 是一个键值存储系统。** 它可以存储一个主键的不同时期的多个版本的值，是谷歌代号为“咖啡因”的最新一代倒排索引引擎的核心。

在“咖啡因”构建倒排索引引擎里，因为 BigTable 这个键值系统的存在，互联网地址可以作为某个 BigTable 的主键使用，因此谷歌不必再把所有互联网地址全部推倒来重新构建索引，而只需要更新那些值已经发生变化的互联网地址。这样一来，网站上出现的新闻可以以秒级的速度被用户搜索到了。

当然，无论是存储还是数据处理的基础架构，适用性都不局限在构建索引上，这些技术渐渐在谷歌内部被广泛应用在其他很多方面。谷歌在发表这些技术的时候，也是把它们作为通用基础架构技术来发表的。

在其他方面的应用，最为著名的是谷歌对用户隐私数据的分析，这些分析促成了谷歌广告业务的蓬勃发展。业界广为流传的互联网模式是“羊毛出在狗身上，猪来买单”，而谷歌就是这个模式的开创者和第一个实践者。

具体来说，谷歌通过提供免费的互联网服务，比如搜索、邮箱、地图等，然后记录并分析用户的使用习惯，有针对性地为用户提供个性化的广告推荐服务。与此同时，谷歌把广告业务卖给其他企业。因为谷歌掌握了大量的数据，其广告推荐服务也非常地高效，所以企业主们愿意为这个服务支付高昂的广告费。

谷歌之所以可以做到个性化推荐，离不开这“三驾马车”：谷歌文件系统和 BigTable 用来存储和记录用户的隐私信息和产品使用情况，MapReduce 用来分析海量数据。

简单来说，**通过掌握“三驾马车”这一利器，谷歌具备了存储和分析海量数据的能力，其个性化广告系统就犹如永动的印钞机，不断地为谷歌赚取财富。这也正是谷歌带给全世界的互联网模式。**

看懂这个互联网模式并不难，难的是除了谷歌，其他互联网公司并没有具备这样强大的数据存储、分析和处理能力。而谷歌并没有打算开放这些独家技术，也不打算通过售卖这些技术给其他互联网公司来赚钱。

这种模式赚钱如流水，因此其他互联网公司都趋之若鹜，希望构建同样强大的数据存储、分析和处理平台。“大数据”这个概念也因此被提出，从此作为一个产业开始爆发。

公允地讲，虽然谷歌扮演了大数据先驱者的角色，但是这个概念并不是它提出来的，而谷歌也从未真正通过给用户提供大数据分析平台服务的方式赚到钱，甚至在后来的 Hadoop 大数据开源社区里也毫无影响力。

除了谷歌，当时有众多互联网企业在诞生和发展，比如 Facebook、LinkedIn，比如当时还如日中天的雅虎，又比如打算和谷歌在搜索领域竞争的微软。当这些公司意识到互联网前进的方向就是那个炙手可热的“大数据”概念，和这个概念下需要的海量存储和数据处理系统时，它们就需要面临艰难的抉择了。

有些公司，比如微软，对自己充满信心，决定像谷歌一样自己构建一套系统。有关微软这套系统的故事，我们会在后续的文章里继续讲解。有些公司，比如雅虎和 Facebook，觉得凭借一己之力很难做到，于是开始抱团取暖，共同构建了后来闻名于世的 Hadoop 生态圈。

凭心而论，在很长一段时间里，Hadoop 和谷歌内部的系统相比非常落后和不堪一击。然而，Hadoop 这个毫无先进性可言的系统，凭借着人多力量大，竟也慢慢成长起来了。 这种成长包括两方面：

- 一方面是，Hadoop 的生态圈越来越大，用的人越来越多。越来越多的用户也在不断刺激着 Hadoop 的创新，这些创新导致 Hadoop 和谷歌的内部技术渐行渐远；
- 另外一方面是，Hadoop 因为用户多，成为了事实上的标准。

待 Hadoop 成气候，受无数人和企业追捧的时候，谷歌那个很先进的“三驾马车”则彻底失去了先机。后来，谷歌开始做云计算，“三驾马车”作为云计算很重要的一部分，谷歌却需要为用户提供 Hadoop 或者类似 Hadoop 的服务。

其中一个服务叫作 HBase，它是 BigTable 在 Hadoop 生态圈里的山寨版。当谷歌试图把自己内部真正的 BigTable 作为云服务提供给用户时，却不得不为 Hadoop 实现 HBase 这个山寨版的接口。本来自己是鼻祖，谷歌现在却必须兼容一个山寨版才能让用户买账，可想而知实现这些接口的程序员们内心肯定在滴血。

谷歌在大数据上，可谓“起个大早，赶个晚集”，最后一无所获。它给大家指明了方向，但是并没有开放它的系统，随后众多互联网公司们联合打造了 Hadoop 生态圈，并让 Hadoop 成为事实上的标准。在这之后，谷歌就彻底丧失了在大数据时代的先发优势。后来谷歌对外提供的云服务也不得不和这个 Hadoop 生态圈兼容。

在我看来，对于这样的结果，也只能怪谷歌自己在开放架构上太过保守了。



# 谷歌的大数据路：一场影响深远的论战

在大数据发展史上有过一场非常著名的论战，这场争议影响深远，值得大书特书：其中一方是数据库领域的元老级人物迈克尔 · 斯通布雷克（Michael Stonebraker）和大卫 · 德威特（David Dewitt）。另外一方是主导了谷歌技术发展的杰夫 · 迪恩（Jeff Dean）。这两群人就谷歌“三架马车”之一的 MapReduce 和数据库到底谁好谁坏，争得不可开交。

在讲述这段故事之前，我先来介绍一下两方的人物。迈克尔是数据库领域的元老级人物，也是这场争议发起者。我们通常把数据库领域的人分为搞理论研究的和做数据库系统研究的两类，而迈克尔当之无愧是数据库系统研究领域最具影响力的人，没有之一。

迈克尔做过很多具有开拓性的事情，这里我就不再一一列举了，拣最最重要地来说。

迈克尔是第一个关系数据库系统 Ingres 的研发者，还是开源数据库系统 Postgres 最早的开发者。Postgres 是目前开源数据库里面最具影响力的项目之一，只有 MySQL 勉强可以匹敌。

同时，迈克尔还是列存数据库 C-Store，以及此后的商用版 Vertica 的开发者。他开发的系统，很多都被公司商业化了。

他还于 2015 年获得了图灵奖，迄今为止数据库领域只有 4 个人获得了这个奖项。他的学生更是遍布整个数据库领域的大学、政府、公司等等。

和迈克尔一同发起这场论战的大卫，曾经是美国威斯康辛大学的教授，退休之后被微软聘用，成为微软的技术院士。他同样也是数据库领域的元老级人物，最初的并行数据库系统和很多算法都是他提出来的。虽然和迈克尔比起来，大卫更加学术一些，但这丝毫没有影响到他在工业界的地位。

这场争论的另外一方人物是谷歌最牛、名气最大的工程师杰夫，他还是美国工程院院士，在谷歌内外都拥有庞大的粉丝群。他参与了谷歌多个重要项目的研发，为谷歌的基础架构研发做出了开创性和奠基性的工作。谷歌“三驾马车”中的 MapReduce 和 BigTable，他都是主要的研发者和设计者，这场论战针对的 MapReduce 就是他最引以为傲的项目。

可以这样说，因为杰夫，谷歌才有了今天的高度。无论是早期基础架构研发的开创性工作，还是后期在人工智能方面的突破，没有杰夫，谷歌不一定能走这么远。但是，我们同样可以说，是谷歌成就了杰夫。因为，只有谷歌才有如此多的数据、计算机资源，和杰出的人才储备，可以让杰夫有足够的发挥空间和平台。

介绍完了相持不下的两方人物，我具体说说这场论战。这场针对 MapReduce 和数据库的争论在 2008 年 1 月 17 日爆发，这一天迈克尔、大卫以及朋友们联合发表了一篇长文“MapReduce: 一个巨大的倒退”（[MapReduce：A major step backwards](https://homes.cs.washington.edu/~billhowe/mapreduce_a_major_step_backwards.html)），开始了对 MapReduce 的围剿。

这篇文章引起了广泛关注和讨论。首先，作者都是计算机行业赫赫有名的人物；其次，文章公然对谷歌宣传的新技术、伟大发明提出质疑。我们知道，这种质疑如果出自你我这样的“吃瓜群众”，谷歌当然不在乎。但如果是泰斗级的人物提出质疑，那就有如“平地一声雷”，每个人都要好好想一想了。

这篇博文的主要观点如下：

1. MapReduce 让人感觉像是生活在原始社会。使用 MapReduce 查询数据时还需要写很多的 C++ 或者 Java 程序，而数据库系统在很多年前就发明了 SQL 语言，通过 SQL 语言本可以很方便地进行数据查询。
2. MapReduce 毫无效率可言。它并不是一个最优实现，现代数据库系统实现多年的性能优化（例如索引），在 MapReduce 里面都没有得到体现。
3. MapReduce 不具创新性。函数式编程语言很早就具备 MapReduce 的语言特性了。
4. MapReduce 不能兼容数据库系统用户已经依赖的所有工具，并且缺乏当前数据库系统拥有的大多数特性。

客观地说，在我这个“吃瓜群众”看来，第一点“感觉像是生活在原始社会”的比喻其实不是问题。因为 Hadoop 生态圈里很快就出现了类似 SQL 的查询语言。如果有需要，谷歌也可以分分钟钟在 MapReduce 里面实现用 SQL 检索数据的功能。

第二点所说的“毫无效率”确实是问题，也是最为大家诟病的问题。后来，整个学术界和工业界围绕 MapReduce 的优化展开的各种工作，无非就是把分布式数据库领域里面实现了很多年的功能重新做了一遍。

至于第三点“MapReduce 不具创新性”，有点儿道理，但也不是什么大问题。函数式编程里面的 Map、Reduce 和谷歌实现的 MapReduce 显然不是同一个概念，它们只是形似而已。而且，创新与否并不是衡量一个系统好坏的标准。

而第四点所说的“和现有数据库工具不兼容”，在我看来就多少有点牵强附会了。因为谷歌内部的系统完全可以形成闭环，不需要兼容外面的数据库工具。而且，和外部数据库的兼容也并不是什么大问题，开源的 Hadoop 社区很快就解决了这个问题。

其实，这篇博文最大的问题是，文中只提到了数据库比 MapReduce 好的方面，却没有说 MapReduce 的优势，因此表述太过偏颇。

相对于数据库系统来说，MapReduce 最主要的优点是提出了在海量的普通廉价个人计算机上，进行稳定的大规模并行计算需要的技术，因为传统意义上的数据库系统都需要很高端的机器来完成同样的任务。

对于数据库系统来说，机器可以随时坏掉，但是系统却必须不间断地运行。因此，数据库系统必须要在稳定可靠的高端机器上运行，并进行冗余备份，来规避机器坏掉的风险。这就在无形中增加了数据库系统运行的成本，而 MapReduce 很好地解决了这个问题。

**这场争论影响广泛，以至于数据库圈子里的很多人都开始站队。有支持甲方迈克尔和大卫的，也有支持乙方杰夫和谷歌的，还有“和稀泥”觉得双方都有道理的。这场争论更是持续了两年之久，“MapReduce 到底是好是坏”也慢慢演变成为了学术圈的一个政治问题。**

2009 年，大卫在 SIGMOD 大会上发表了一篇论文：《大规模数据分析方法对比》（[*A comparison of approaches to large-scale data analysis*](http://www.science.smith.edu/dftwiki/images/6/6a/ComparisonOfApproachesToLargeScaleDataAnalysis.pdf)**）**。论文比较了 MapReduce 在 Hadoop 开源社区中的实现和数据库系统的性能，并得出了数据库系统性能要好很多的结论。当时，我就在 SIGMOD 的现场，论文宣讲结束后，无数人质疑这篇论文的评价方式是否公平。

我印象最为深刻的是，数据库领域的知名学者拉 · 罗摩克里希纳恩（Raghu Ramakrishnan）当场就提出了质疑。他曾经和大卫同为威斯康辛大学的教授，不久前加入了雅虎研究院，并负责数据库研究工作。而雅虎是 Hadoop 的主导者，所以通常和大卫意见一致的他，这次却对这篇论文的内容表示了强烈反对。在我看来，这更多的就是政治立场的不同了。

更加不可思议的是，美国计算机协会 ACM 的重要刊物 _Communications of the ACM_ 也介入进了这场论战。这个杂志是美国计算机协会的会刊，通常刊登一些在计算机领域比较有影响力的文章。

2010 年的第 1 期刊登了涉及这场争论的两篇论文：《MapReduce 和并行数据库：是朋友还是敌人？》（MapReduce and Parallel DBMSs：Friends or Foes？）和《MapReduce：一个灵活的数据库处理工具》（MapReduce：A Flexible Data Processing Tool）。

虽然两篇文章都互相引用了对方的观点，但很大程度上还是自说自话。据我所知，这是 _Communications of the ACM_ 第一次刊登这种类型的文章，这也说明论战已经影响到整个计算机领域，不再仅仅局限于数据库的圈子了，可谓“一石激起千层浪”。

**这场论战的深远影响还体现在，很多人都对这场论战的两方观点进行了认真思考，并希望可以扬长避短开发出更好的系统。但是，真正把从这场论战中得到的反思成功付诸实际行动的，就只有加州伯克利大学 AMP 实验室里的那群人了，他们发明了一个叫作 Spark 的计算引擎。**

Spark 项目的重要负责人之一迈克尔 · 富兰克林（Michael Franklin）在 2017 年的国际数据库顶级会议[VLDB (International Conference of Very Large Data Base）](http://www.vldb.org/2017/keynotes.php)上做了一个主题演讲：《大数据软件路在何方》（[**Big Data Software: What’s Next?**](http://www.vldb.org/2017/download/2017-08-30-VLDB-Keynote_Michael_Franklin.pdf) **）****，**主要内容就是“Spark 是如何诞生的”。

在主题报告上，他提到了这场论战，当时整个 AMP 实验室的教授们都在思考这两方到底谁更有道理。经过非常深入地思考和论证，AMP 实验室的教授们决定吸取 MapReduce 和数据库系统两方的精华，同时抛弃这两方不合理的地方，从头开始构建一个大数据计算引擎。于是，Spark 在这样的背景下诞生了。

目前来看，Spark 非常得成功。它既不是数据库，也不像 MapReduce。在某种程度上来说，Spark 是两者的结合，又有自己的创新。现在，Spark 归属于这群人的创业公司 Databricks，有关 Spark 和 Databricks 的故事我会在这个系列后续的文章里详细讲解。

这次针对 MapReduce 和数据库的大论战，最后伴随着 Spark 的诞生也就有了结果。





# 谷歌的大数据路：一场影响深远的论战

在大数据发展史上有过一场非常著名的论战，这场争议影响深远，值得大书特书：其中一方是数据库领域的元老级人物迈克尔 · 斯通布雷克（Michael Stonebraker）和大卫 · 德威特（David Dewitt）。另外一方是主导了谷歌技术发展的杰夫 · 迪恩（Jeff Dean）。这两群人就谷歌“三架马车”之一的 MapReduce 和数据库到底谁好谁坏，争得不可开交。

在讲述这段故事之前，我先来介绍一下两方的人物。迈克尔是数据库领域的元老级人物，也是这场争议发起者。我们通常把数据库领域的人分为搞理论研究的和做数据库系统研究的两类，而迈克尔当之无愧是数据库系统研究领域最具影响力的人，没有之一。

迈克尔做过很多具有开拓性的事情，这里我就不再一一列举了，拣最最重要地来说。

迈克尔是第一个关系数据库系统 Ingres 的研发者，还是开源数据库系统 Postgres 最早的开发者。Postgres 是目前开源数据库里面最具影响力的项目之一，只有 MySQL 勉强可以匹敌。

同时，迈克尔还是列存数据库 C-Store，以及此后的商用版 Vertica 的开发者。他开发的系统，很多都被公司商业化了。

他还于 2015 年获得了图灵奖，迄今为止数据库领域只有 4 个人获得了这个奖项。他的学生更是遍布整个数据库领域的大学、政府、公司等等。

和迈克尔一同发起这场论战的大卫，曾经是美国威斯康辛大学的教授，退休之后被微软聘用，成为微软的技术院士。他同样也是数据库领域的元老级人物，最初的并行数据库系统和很多算法都是他提出来的。虽然和迈克尔比起来，大卫更加学术一些，但这丝毫没有影响到他在工业界的地位。

这场争论的另外一方人物是谷歌最牛、名气最大的工程师杰夫，他还是美国工程院院士，在谷歌内外都拥有庞大的粉丝群。他参与了谷歌多个重要项目的研发，为谷歌的基础架构研发做出了开创性和奠基性的工作。谷歌“三驾马车”中的 MapReduce 和 BigTable，他都是主要的研发者和设计者，这场论战针对的 MapReduce 就是他最引以为傲的项目。

可以这样说，因为杰夫，谷歌才有了今天的高度。无论是早期基础架构研发的开创性工作，还是后期在人工智能方面的突破，没有杰夫，谷歌不一定能走这么远。但是，我们同样可以说，是谷歌成就了杰夫。因为，只有谷歌才有如此多的数据、计算机资源，和杰出的人才储备，可以让杰夫有足够的发挥空间和平台。

介绍完了相持不下的两方人物，我具体说说这场论战。这场针对 MapReduce 和数据库的争论在 2008 年 1 月 17 日爆发，这一天迈克尔、大卫以及朋友们联合发表了一篇长文“MapReduce: 一个巨大的倒退”（[MapReduce：A major step backwards](https://homes.cs.washington.edu/~billhowe/mapreduce_a_major_step_backwards.html)），开始了对 MapReduce 的围剿。

这篇文章引起了广泛关注和讨论。首先，作者都是计算机行业赫赫有名的人物；其次，文章公然对谷歌宣传的新技术、伟大发明提出质疑。我们知道，这种质疑如果出自你我这样的“吃瓜群众”，谷歌当然不在乎。但如果是泰斗级的人物提出质疑，那就有如“平地一声雷”，每个人都要好好想一想了。

这篇博文的主要观点如下：

1. MapReduce 让人感觉像是生活在原始社会。使用 MapReduce 查询数据时还需要写很多的 C++ 或者 Java 程序，而数据库系统在很多年前就发明了 SQL 语言，通过 SQL 语言本可以很方便地进行数据查询。
2. MapReduce 毫无效率可言。它并不是一个最优实现，现代数据库系统实现多年的性能优化（例如索引），在 MapReduce 里面都没有得到体现。
3. MapReduce 不具创新性。函数式编程语言很早就具备 MapReduce 的语言特性了。
4. MapReduce 不能兼容数据库系统用户已经依赖的所有工具，并且缺乏当前数据库系统拥有的大多数特性。

客观地说，在我这个“吃瓜群众”看来，第一点“感觉像是生活在原始社会”的比喻其实不是问题。因为 Hadoop 生态圈里很快就出现了类似 SQL 的查询语言。如果有需要，谷歌也可以分分钟钟在 MapReduce 里面实现用 SQL 检索数据的功能。

第二点所说的“毫无效率”确实是问题，也是最为大家诟病的问题。后来，整个学术界和工业界围绕 MapReduce 的优化展开的各种工作，无非就是把分布式数据库领域里面实现了很多年的功能重新做了一遍。

至于第三点“MapReduce 不具创新性”，有点儿道理，但也不是什么大问题。函数式编程里面的 Map、Reduce 和谷歌实现的 MapReduce 显然不是同一个概念，它们只是形似而已。而且，创新与否并不是衡量一个系统好坏的标准。

而第四点所说的“和现有数据库工具不兼容”，在我看来就多少有点牵强附会了。因为谷歌内部的系统完全可以形成闭环，不需要兼容外面的数据库工具。而且，和外部数据库的兼容也并不是什么大问题，开源的 Hadoop 社区很快就解决了这个问题。

其实，这篇博文最大的问题是，文中只提到了数据库比 MapReduce 好的方面，却没有说 MapReduce 的优势，因此表述太过偏颇。

相对于数据库系统来说，MapReduce 最主要的优点是提出了在海量的普通廉价个人计算机上，进行稳定的大规模并行计算需要的技术，因为传统意义上的数据库系统都需要很高端的机器来完成同样的任务。

对于数据库系统来说，机器可以随时坏掉，但是系统却必须不间断地运行。因此，数据库系统必须要在稳定可靠的高端机器上运行，并进行冗余备份，来规避机器坏掉的风险。这就在无形中增加了数据库系统运行的成本，而 MapReduce 很好地解决了这个问题。

**这场争论影响广泛，以至于数据库圈子里的很多人都开始站队。有支持甲方迈克尔和大卫的，也有支持乙方杰夫和谷歌的，还有“和稀泥”觉得双方都有道理的。这场争论更是持续了两年之久，“MapReduce 到底是好是坏”也慢慢演变成为了学术圈的一个政治问题。**

2009 年，大卫在 SIGMOD 大会上发表了一篇论文：《大规模数据分析方法对比》（[*A comparison of approaches to large-scale data analysis*](http://www.science.smith.edu/dftwiki/images/6/6a/ComparisonOfApproachesToLargeScaleDataAnalysis.pdf)**）**。论文比较了 MapReduce 在 Hadoop 开源社区中的实现和数据库系统的性能，并得出了数据库系统性能要好很多的结论。当时，我就在 SIGMOD 的现场，论文宣讲结束后，无数人质疑这篇论文的评价方式是否公平。

我印象最为深刻的是，数据库领域的知名学者拉 · 罗摩克里希纳恩（Raghu Ramakrishnan）当场就提出了质疑。他曾经和大卫同为威斯康辛大学的教授，不久前加入了雅虎研究院，并负责数据库研究工作。而雅虎是 Hadoop 的主导者，所以通常和大卫意见一致的他，这次却对这篇论文的内容表示了强烈反对。在我看来，这更多的就是政治立场的不同了。

更加不可思议的是，美国计算机协会 ACM 的重要刊物 _Communications of the ACM_ 也介入进了这场论战。这个杂志是美国计算机协会的会刊，通常刊登一些在计算机领域比较有影响力的文章。

2010 年的第 1 期刊登了涉及这场争论的两篇论文：《MapReduce 和并行数据库：是朋友还是敌人？》（MapReduce and Parallel DBMSs：Friends or Foes？）和《MapReduce：一个灵活的数据库处理工具》（MapReduce：A Flexible Data Processing Tool）。

虽然两篇文章都互相引用了对方的观点，但很大程度上还是自说自话。据我所知，这是 _Communications of the ACM_ 第一次刊登这种类型的文章，这也说明论战已经影响到整个计算机领域，不再仅仅局限于数据库的圈子了，可谓“一石激起千层浪”。

**这场论战的深远影响还体现在，很多人都对这场论战的两方观点进行了认真思考，并希望可以扬长避短开发出更好的系统。但是，真正把从这场论战中得到的反思成功付诸实际行动的，就只有加州伯克利大学 AMP 实验室里的那群人了，他们发明了一个叫作 Spark 的计算引擎。**

Spark 项目的重要负责人之一迈克尔 · 富兰克林（Michael Franklin）在 2017 年的国际数据库顶级会议[VLDB (International Conference of Very Large Data Base）](http://www.vldb.org/2017/keynotes.php)上做了一个主题演讲：《大数据软件路在何方》（[**Big Data Software: What’s Next?**](http://www.vldb.org/2017/download/2017-08-30-VLDB-Keynote_Michael_Franklin.pdf) **）****，**主要内容就是“Spark 是如何诞生的”。

在主题报告上，他提到了这场论战，当时整个 AMP 实验室的教授们都在思考这两方到底谁更有道理。经过非常深入地思考和论证，AMP 实验室的教授们决定吸取 MapReduce 和数据库系统两方的精华，同时抛弃这两方不合理的地方，从头开始构建一个大数据计算引擎。于是，Spark 在这样的背景下诞生了。

目前来看，Spark 非常得成功。它既不是数据库，也不像 MapReduce。在某种程度上来说，Spark 是两者的结合，又有自己的创新。现在，Spark 归属于这群人的创业公司 Databricks，有关 Spark 和 Databricks 的故事我会在这个系列后续的文章里详细讲解。

这次针对 MapReduce 和数据库的大论战，最后伴随着 Spark 的诞生也就有了结果。





# 谷歌的大数据路：谷歌的“黑科技”

**谷歌的大数据之路，上半场以“三驾马车”（谷歌文件系统、MapReduce 和 BigTable）开始，却以被 Hadoop 开源生态系统全面山寨了自己的“三驾马车”而结束。**

此后，开源社区不断推陈出新，推出了连谷歌都没有的开源项目，并将其融入了 Hadoop 生态系统。从此，Hadoop 生态系统成为了大数据领域事实上的标准，而谷歌也不得不在自己的云计算平台上提供对 Hadoop 开源山寨项目的兼容性支持。

最终，在大数据的上半场，随着 Hadoop 生态圈的崛起，谷歌在大数据领域的影响力荡然无存。

然而，谷歌也不是吃素的。**在大数据的下半场，谷歌携带“黑科技”Spanner 数据库系统闪亮登场了。** 在讲这个“黑科技”前，我们先来看看谷歌“三驾马车”里的 BigTable。虽然 BigTable 名字里面包含了“Table”，但实际上它并不是一个数据库的表，它只是一个键值存储系统（即 Key-Value Store）。

一方面，BigTable 虽然可以处理大规模高并发的查询，但是这个查询功能并不好用。在 BigTable 中用户无法使用 SQL 进行数据查询，而必须采用编程的方式，这就导致数据查询的用户体验非常不好。因此，应用程序开发者更愿意选择用他们熟悉的数据库系统，通过 SQL 完成数据访问和查询。

另外一方面，虽然谷歌的搜索系统构建在“三驾马车”上，但广告引擎并不是。在很长一段时间里，谷歌的广告引擎都是采用开源的关系数据库 MySQL。但是随着谷歌业务的发展，MySQL 越来越无法支撑谷歌广告业务的发展。

基于以上两方面的诉求，谷歌需要再开发一个数据库系统，这个系统既要有 BigTable 处理大规模高并发查询的能力，又要能够支持 SQL 查询和事务处理。这个系统就是今天的主角，后来赫赫有名的“黑科技”Spanner：谷歌的跨洲多数据中心的数据库。

那么，Spanner 到底是什么呢？

- 首先，它是一个数据库，支持 SQL 查询，类似于 Oracle 或者微软的 SQL Server，以及开源的 MySQL、Postgres 等。
- 其次，Spanner 跟其他数据库系统最大的不同是，它支持把数据存储在谷歌全球各地的不同的数据中心里，并且对这些数据进行查询。同时，它还能够保证这些跨洲多数据中心数据的一致性。

目前这个系统，全球只此一家别无分号。有传闻说，亚马逊屡次试图实现 Spanner 这样的系统，但是屡战屡败，屡败屡战，现在依旧没有什么进展。

**众所周知，时间问题是分布式系统里面最难解决的问题。** 每台机器上细小的时间差别，反应到全局的结果就是没有统一的时间观念。

在同一个数据中心，通过时间同步协议定期对所有机器进行时间同步，这个时间问题就可以迎刃而解了。但是，一旦数据中心跨洲后，通过同步协议进行定期更新的做法就不切实际了。因为，利用同步协议更新跨洲数据中心的时间所要耗费的时间本身，就已经可以产生了不可忽略的误差。而 Spanner 被称为“黑科技”的原因之一就是，它开创性地采用了原子钟和 GPS 全球定位系统，从而解决了这个跨洲的全球数据中心的时间同步问题。

在最开始，谷歌只做了 Spanner 的存储层实现，虽然解决了全球数据中心的时间同步问题，但是并不能满足谷歌广告引擎业务的需要。主要原因是，在 Spanner 中存储层的访问需要使用底层的 API，而广告系统是通过 SQL 访问 MySQL 集群的，这是一种高层的数据访问查询方式。而这时，谷歌将广告系统从 MySQL 集群迁移出来的需求也不断增长，于是就专门组建了一个技术团队，这个团队的任务就是基于 Spanner 的存储层开发一个新的数据库系统 F1。

最终，F1 研发成功了。F1 的成功主要体现在两个方面。

- 首先，F1 是一个完整的数据库，可以兼容 MySQL，广告部门基本上不需要改代码就可以通过 SQL 访问 F1 数据库。
- 其次，F1 的扩展性非常好，可以进行任意的扩展，包括跨地域的扩展，因此广告部门再也不需要因为流量的增加而手动扩展 MySQL 集群了。

因此，谷歌终于有了属于自己的跨地域的全球性数据库。这个数据库提供了极大的便利性，从此谷歌的广告业务终于可以脱离 MySQL 了，谷歌也因此获得了许多新的收入。

然而，虽然 F1 系统解决了谷歌广告业务受制于 MySQL 的问题，但是这个系统有一个最大的问题：它完全是为谷歌的广告业务定制的，也因此无法应用在谷歌的其他项目上。

比如，F1 数据库把表按照广告客户 ID 进行分区，数据在这些静态分区之间没法进行迁移。其他的项目都有自己的数据库表方式，而改造成 F1 数据库表方式是一个非常巨大的工作量，这也就导致了非广告业务无法实施在 F1 数据库系统上。

这时，谷歌内部对构建一个通用的数据库系统的诉求愈发强烈。一方面，F1 数据库和广告业务紧紧耦合，且 F1 的团队也没时间做解耦来消除这种局限性；另一方面，Spanner 团队发现他们需要在存储层上开发一些新的东西。

在这样的背景下，Spanner 团队开始自己做执行层的开发。这样一来，Spanner 被开发地越来越像是一个完备的数据库。经过几年的演变以后，Spanner 最终成为了一个完备的数据库。

这样，**谷歌内部就有了两套基于 Spanner 存储层的数据库了：Spanner 团队自己开发的和广告组开发的 F1 数据库。** 这两套系统在谷歌内部开展了广泛的竞争，最终的结果就是：非广告业务都采用 Spanner 组开发的系统，而广告业务部则用 F1。而在外界，很多人被谷歌这两套系统搞蒙了，大家一直误会 F1 和 Spanner 是同一个产品，但事实上它们是功能和适用范围都不同的两个系统。

- F1 开发得比较早，是针对广告部门定制的数据库系统。这个系统在广告相关业务上性能非常好，但缺失了很多支撑其他业务必要的功能，所以通用性很差。
- Spanner 团队则开发了一个通用的数据库系统，具备了数据库系统的所有功能。但是这个系统没有专门针对广告业务进行优化，因此应用在广告系统上的性能要差一些。

虽然有这些小插曲，但是自从有了 Spanner，谷歌的底气就不一样了。这个黑科技支持的数据库，使谷歌第一次做到了进行全球范围的事务处理，这确实是史无前例的。**鉴于开放“三驾马车”架构时的保守性，让谷歌丧失了在大数据时代的先发优势，这次谷歌决定把 Spanner 放到云上供大家使用，并将其命名为 Cloud Spanner。**

谷歌试图通过 Cloud Spanner 这个高大上的“黑科技”来推动云端大数据产品的销售，但是却没有达到预期效果。在我看来，Cloud Spanner 发展不顺利的原因主要有两个：

1. Spanner 收费非常昂贵，对用户来说不够经济实惠；
2. 大部分用户都没有谷歌那么大的数据量，跨大洲、跨大洋的数据库功能对他们来说，多少有点华而不实。

虽然 Spanner 在云端客户上发展并不顺利，但是有些情况也只有 Spanner 这样的数据库才可以从容应对。比如，中国的金融行业需要两地三中心的架构，这种架构目前主要通过高端机器实现。即便如此，金融机构也无法避免真正可能发生的灾难。但是，如果换成 Spanner，金融机构不但能够更好地自动应对故障的发生，而且可以降低成本。

无论结果怎样，Spanner 让谷歌再次在大数据领域吸引了很多关注。谷歌通过无与伦比的技术实力告诉大家，它才是大数据技术真正的推动者。但是 Spanner 这个“黑科技”也只对谷歌这种规模的数据有现实意义，而对其他企业来说并不是刚需。所以，Spanner 终究还是落得了“叫好不叫座”的结局。







# 如何读懂类似谷歌“三驾马车”这样的技术论文？

在信息化时代，技术发展日新月异，知识更新的速度也是越来越快。以前我们可以安安稳稳地坐在教室里，等到一本写得不错的教材出来，再去系统地学习知识。而现在，我们却必须选择去读那些最新发表出来的技术论文，因为只有这样才能赶得上时代发展的潮流。

**作为互联网行业的软件从业人员，能不能读懂论文，是一项可以决定自己发展潜力的必备技能**。

然而，读懂论文并不容易，这比读懂一本书要难多了。在我看来，读懂一篇技术论文是需要技巧的。

作为一个美国大学毕业的 PhD，曾先后在各种顶级会议和期刊上发表过十几篇论文的作者，**我觉得可以从论文写作的角度，跟你谈一谈论文和教科书的区别，帮助你理解怎么读论文才是一个相对正确而又省力的过程。**

**要理解为什么技术论文难以读懂，你首先要弄明白一个问题：论文到底是写给谁看的？**

目前发表在顶级期刊或者会议上的论文，包括非常经典的谷歌“三驾马车”的论文，都是为了给这个领域的专家看的，而不是要写给广大程序员看的。因此，这些论文也就不太可能普遍照顾到程序员的理解能力。

关于作者在写作论文时会预先设定目标读者这一点，我们可以从以下两个方面来理解。

1. 顶级期刊或者会议发表的论文都是需要经过同行评审的。同行评审是很关键的一步，论文能否录取，往往取决于跟你处在同一个水平或者更权威的专家对论文内容的判断和评价。所以，论文首先就是写给同行专家看的，否则是无法通过同行评审这一关的，那论文发表又从何谈起呢？
2. 论文发表的目的是什么？其实，发表论文的目的有很多。在学术界，发表论文就是工作的一部分，目的就是宣示你做了很多、很有影响力的研究；在工业界，发表论文的目的就更多了，但树立自己在业界的领先地位这一点是毫无疑问的。

理解了“论文到底是写给谁看的”这个问题，我们再**来看下一个问题：论文通常都是怎么写出来的？**这是个非常复杂的问题，我会一点一点地分解剖析。

**首先，论文作者对同行的知识结构是有假设的。** 和教科书非常不同，论文作者首先会假设同行对这个领域的基础性研究和相关知识都已经非常熟悉了，因此只在非常必要或者特殊情况下才会去介绍特定的知识。而在大部分情况下，论文作者给出一个引用已经是很奢侈的事情了。这意味着什么呢？如果你连这个领域的基础知识都不懂，是没有办法一上手就读懂论文的。

举个例子，如果你去看大数据基础架构的论文，比如谷歌的“三驾马车”的论文，倘若你连最基本的分布式系统知识都没有，那无异于是“小孩子读微积分”；倘若机器学习的知识你一点儿都不懂，那一篇讨论深度学习的论文对你来说，无异于“天书”。

因此，作为一个读者，你能不能读懂一篇论文，直接取决于你自己在这个领域中的基础知识积累。所以，**想要有阅读论文的能力，首先要把基础知识补好。**

**其次，论文里面的内容都是“化了妆”的。** 学术圈有一个基本规则，简单地说就是：不可以在论文里面说谎。然而，“不说谎”不代表作者要把自己做的系统的方方面面都说出来，换个说法就是：作者可以对系统的缺点轻描淡写，能简单就简单；而对系统的优点和先进性大书特书，极力营造为“天上没有，人间极品”的效果。因此，在不违背基本原则的前提下，作者在论文里有选择性地写作，是学术圈里公认的套路。

这就意味着，**读者要带着批判性去读论文，而不能按照读教科书的思路去读。教科书的作者在写作时一般都会做到客观公正、深入浅出，而这很显然不是论文作者的写作方法。** 因此，对于作者语焉不详的地方要多问几个为什么，对于作者自夸的地方要认真思考一下是不是真的牛。其实，这些都是读懂论文的基本功。

那这种基本功从何而来呢？总结起来，我觉得可以从以下三个方面来获得这些基本功。

1. **自己撰写论文，然后努力发表。** 这个办法比较奢侈也比较痛苦，而且见效较慢。但是一旦成功，效果往往是其他办法不能比的。即便没有成功发出论文来，你也可以从论文的写作过程中学到很多知识。
    所以，在有条件发表论文的情况下，一定要不惜代价地尝试。即使最后一篇论文也没发出来，但这种尝试也绝对有好处。最明显的好处就是，可以帮助你理解论文写作过程中要展现好的一面、掩藏坏的一面，理解作者在论文中没写的那部分到底是什么。
2. **找到两篇可以比较的论文：后者引用前者，和前者的方法进行比较，并在前者的基础上有所提高。** 这时，你可以拿着前者的文章，看看作者是如何“吹牛”的、又是如何避免谈缺陷的，而后者又是如何表明自己弥补了前者不足的。通过比较前后两篇论文的内容，可以有效地提高你用批判性思维阅读论文的能力。
    但是，这个方法对系统性的文章，比如谷歌的“三驾马车”这类的文章，不是特别适用。主要原因是，这类文章表述的系统往往是从无到有的原创性系统，也只有谷歌这样的大型科技公司才有能力去开发这样的系统。一般来说，是无法找到可以相比较的文章的。
3. **一定要认识到论文中一般只交代作者成功的故事，而对于成功背后无数次失败的尝试这样的内容绝少出现。** 这就意味着，你看到的只是作者成功的解决方案。有过基础研究的人很清楚地知道，任何一篇论文背后都隐藏着无数次失败的尝试。对于系统论文、大数据论文，这个规律依然适用。
    比如，在微软、百度、阿里巴巴做过类似于谷歌“三驾马车”的系统开发人员，这些人虽然还没有成功，但是经历了多次类似的失败，已经足够体会到经验背后的教训了，因而可以比较轻松地读懂这些论文。而对其他没有类似体验的人来说，就很难了。

所以有些论文你读不懂，其实是因为论文中缺乏对系统研究过程中失败尝试的描述，而你也没有过开发类似系统的体验。因此，**从这个角度来讲，最能读懂论文的，往往都是那些从事过类似系统开发的人。**

关于这一点，我认为比较好的解决办法只有两个。

1. 加入一个团队进行类似的系统开发，毕竟“纸上得来终觉浅”。
2. 找到这篇论文在各大网站上的相关解读，以及论文作者此后演讲的相关材料，这些资料往往是帮助你理解论文的最佳途径。在这些演讲材料中，作者往往会更自由地分享一些成功的经验、失败的教训。而在论文发表时，因为同行评审等压力，往往会有所忌讳，所以不会分享的太全面。

写到这里，我需要特别指出一类比较特殊的论文，就是综述性质的论文。这种论文，往往是由业界大佬就这个领域在某段时间内的所有研究工作汇总而成，是最接近教科书的论文。

除了阅读综述性论文以外，你还可以参加一些行业的顶级会议。这些顶级会议除了论文宣讲，还会邀请行业大佬举行一些综述性质的讲座。这些讲座的内容往往更客观公正、逻辑性更强，也比较像教科书，更容易被听众理解。但是，这些讲座通常不会被发表成论文，只有现场的参会人员才可以听到。

总结来讲，论文难懂是正常情况。要想读懂论文，你需要明白论文是写给谁看的、是怎么写的。作为读者，你首先要提高自己的领域基础知识，然后明白论文的一些基本套路，这会让你在阅读论文时更容易读懂、更有收获。最后，综述性质的论文很像教科书，特别适合用于特定领域的入门。













